{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[],"dockerImageVersionId":31192,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import os\nimport json\nfrom kaggle_secrets import UserSecretsClient\nfrom openai import OpenAI\n\n# Read the API key from Kaggle secrets\nuser_secrets = UserSecretsClient()\napi_key = user_secrets.get_secret(\"OPENAI_API_KEY\")  # must match your secret name\n\nif not api_key:\n    raise RuntimeError(\n        \"Could not read OPENAI_API_KEY from Kaggle secrets. \"\n    )\n\n# Create the OpenAI client (v1-style)\nclient = OpenAI(api_key=api_key)\n\nMODEL_NAME = \"gpt-4o-mini\"  # or another chat-capable model available to your account\n\nSYSTEM_PROMPT = (\n    \"You are an AI agent that first analyzes the user's message and then replies.\\n\"\n    \"1. Decide the high-level intent of the user in a few words.\\n\"\n    \"2. Estimate the overall sentiment as one of: 'positive', 'neutral', or 'negative'.\\n\"\n    \"3. Write a clear, helpful reply.\\n\\n\"\n    \"Return your answer strictly as JSON with the keys:\\n\"\n    \"{\\n\"\n    '  \\\"intent\\\": \\\"<short_intent>\\\",\\n'\n    '  \\\"sentiment\\\": \\\"<positive|neutral|negative>\\\",\\n'\n    \" \\\"reply\\\": \\\"<your natural language response>\\\"\\n\"\n    \"}\\n\"\n)\n\n# 2. Core agent function (new API)\n\ndef analyze_and_respond(user_message: str) -> dict:\n    \"\"\"\n    Send the user's message to the OpenAI chat model and return:\n    - intent (str)\n    - sentiment (str)\n    - reply (str)\n    \"\"\"\n    completion = client.chat.completions.create(\n        model=MODEL_NAME,\n        messages=[\n            {\"role\": \"system\", \"content\": SYSTEM_PROMPT},\n            {\"role\": \"user\", \"content\": user_message},\n        ],\n        temperature=0.7,\n        max_tokens=300,\n    )\n\n    raw_content = completion.choices[0].message.content\n\n    try:\n        data = json.loads(raw_content)\n    except json.JSONDecodeError:\n        data = {\n            \"intent\": \"unknown\",\n            \"sentiment\": \"neutral\",\n            \"reply\": raw_content.strip(),\n        }\n\n    return {\n        \"intent\": str(data.get(\"intent\", \"unknown\")),\n        \"sentiment\": str(data.get(\"sentiment\", \"neutral\")),\n        \"reply\": str(data.get(\"reply\", raw_content)).strip(),\n    }\n\n# 3. Simple interactive loop (unchanged)\n\ndef chat_loop() -> None:\n    \"\"\"\n    Run an interactive console loop where the user can chat with the agent.\n    \"\"\"\n    print(\"=== Simple AI Agent (intent + sentiment + reply) ===\")\n\n    while True:\n        user_message = input(\"You: \").strip()\n        if not user_message:\n            continue\n\n        if user_message.lower() in {\"exit\", \"quit\", \"q\"}:\n            print(\"Agent: Goodbye!\")\n            break\n\n        analysis = analyze_and_respond(user_message)\n\n        intent = analysis[\"intent\"]\n        sentiment = analysis[\"sentiment\"]\n        reply = analysis[\"reply\"]\n\n        print(f\"[Intent: {intent} | Sentiment: {sentiment}]\")\n        print(f\"Agent: {reply}\\n\")\n\n\nif __name__ == \"__main__\":\n    chat_loop()","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# Simple AI Agent using LangChain (RunnableLambda), rule-based analysis, and templated replies.","metadata":{}},{"cell_type":"code","source":"!pip install -q \"protobuf<6\" --quiet\n!pip install \"langchain_huggingface\" --quiet","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import re\nfrom typing import Dict\n\nfrom langchain_core.runnables import RunnableLambda\n\n\n# ---------------------------------------------------------------------\n# 1. Lightweight intent + sentiment analysis\n# ---------------------------------------------------------------------\n\ndef detect_intent(text: str) -> str:\n    \"\"\"Very simple rule-based intent classifier.\"\"\"\n    lowered = text.lower()\n\n    if any(word in lowered for word in [\"hi\", \"hello\", \"hey\", \"good morning\", \"good evening\"]):\n        return \"greeting\"\n\n    if any(phrase in lowered for phrase in [\"thank you\", \"thanks\", \"appreciate it\"]):\n        return \"gratitude\"\n\n    if any(word in lowered for word in [\"help\", \"how do i\", \"how to\", \"can you\", \"could you\", \"what can you\"]):\n        return \"information_request\"\n\n    if any(word in lowered for word in [\"bye\", \"goodbye\", \"see you\", \"later\"]):\n        return \"farewell\"\n\n    # Fallback if nothing obvious matched\n    return \"general_conversation\"\n\n\ndef analyze_sentiment(text: str) -> str:\n    \"\"\"\n    Tiny keyword-based sentiment estimator.\n\n    Counts positive/negative words and compares their scores.\n    This is deliberately simple, but enough to demonstrate analysis.\n    \"\"\"\n    lowered = text.lower()\n\n    positive_words = [\n        \"good\", \"great\", \"awesome\", \"love\", \"like\",\n        \"happy\", \"nice\", \"amazing\", \"fantastic\", \"cool\",\n    ]\n    negative_words = [\n        \"bad\", \"terrible\", \"hate\", \"dislike\",\n        \"sad\", \"angry\", \"upset\", \"worried\",\n        \"annoyed\", \"frustrated\",\n    ]\n\n    pos_score = sum(1 for w in positive_words if re.search(rf\"\\b{re.escape(w)}\\b\", lowered))\n    neg_score = sum(1 for w in negative_words if re.search(rf\"\\b{re.escape(w)}\\b\", lowered))\n\n    if pos_score > neg_score:\n        return \"positive\"\n    if neg_score > pos_score:\n        return \"negative\"\n    return \"neutral\"\n\n\n# ---------------------------------------------------------------------\n# 2. Analysis + reply functions (pure Python)\n# ---------------------------------------------------------------------\n\ndef analyze_message(user_text: str) -> Dict[str, str]:\n    \"\"\"\n    Step 1: Given the raw user text, compute intent and sentiment.\n    This is the first stage in the LangChain pipeline.\n    \"\"\"\n    intent = detect_intent(user_text)\n    sentiment = analyze_sentiment(user_text)\n\n    return {\n        \"text\": user_text,\n        \"intent\": intent,\n        \"sentiment\": sentiment,\n    }\n\n\ndef craft_reply(analysis: Dict[str, str]) -> Dict[str, str]:\n    \"\"\"\n    Step 2: Given the analysis dict, generate a short, clear reply.\n    This is deterministic and rule-based (no external model).\n    \"\"\"\n    text = analysis[\"text\"]\n    intent = analysis[\"intent\"]\n    sentiment = analysis[\"sentiment\"]\n\n    # Base reply per intent\n    if intent == \"greeting\":\n        reply = \"Hello! I am a simple AI agent here to chat with you and answer basic questions.\"\n    elif intent == \"gratitude\":\n        reply = \"You are welcome; glad I could help.\"\n    elif intent == \"information_request\":\n        reply = \"I can explain what I am, what I can do, or help you think through simple questions step by step.\"\n    elif intent == \"farewell\":\n        reply = \"Goodbye! It was nice talking with you.\"\n    else:\n        reply = \"I am an AI agent that analyzes your message and replies with a short, helpful response.\"\n\n    # Very light sentiment-aware adjustment\n    if sentiment == \"negative\" and intent not in {\"farewell\", \"gratitude\"}:\n        reply += \" I am sorry that things feel difficult; I will try to respond in a calm and supportive way.\"\n    elif sentiment == \"positive\" and intent not in {\"farewell\", \"gratitude\"}:\n        reply += \" It sounds like you are feeling positive, which is great.\"\n\n    # Add original text to the dict in case you want to log it later\n    return {\n        \"text\": text,\n        \"intent\": intent,\n        \"sentiment\": sentiment,\n        \"reply\": reply,\n    }\n\n\n# ---------------------------------------------------------------------\n# 3. Build a LangChain pipeline from these functions\n# ---------------------------------------------------------------------\n\n# Wrap the plain Python functions as LangChain Runnables\nanalysis_runnable = RunnableLambda(analyze_message)\nreply_runnable = RunnableLambda(craft_reply)\n\n# Chain them: user_text (str) -> analysis dict -> dict with reply\nagent_chain = analysis_runnable | reply_runnable\n\n\n# ---------------------------------------------------------------------\n# 4. Simple console chat loop\n# ---------------------------------------------------------------------\n\ndef chat_loop() -> None:\n    \"\"\"\n    Run a text-based chat loop.\n\n    Type 'exit', 'quit', or 'q' to stop.\n    \"\"\"\n    print(\"=== Simple LangChain AI Agent (rule-based) ===\")\n    print(\"Type 'exit', 'quit', or 'q' to end the conversation.\\n\")\n\n    while True:\n        user_text = input(\"You: \").strip()\n        if not user_text:\n            continue\n\n        if user_text.lower() in {\"exit\", \"quit\", \"q\"}:\n            print(\"Agent: Goodbye!\")\n            break\n\n        # Use the LangChain pipeline to process the message\n        result = agent_chain.invoke(user_text)\n\n        print(f\"[Intent: {result['intent']} | Sentiment: {result['sentiment']}]\")\n        print(f\"Agent: {result['reply']}\\n\")\n\n\n# Only run the loop if this file / cell is executed directly\nif __name__ == \"__main__\":\n    chat_loop()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-19T18:13:05.820851Z","iopub.execute_input":"2025-11-19T18:13:05.821177Z","iopub.status.idle":"2025-11-19T18:14:43.565248Z","shell.execute_reply.started":"2025-11-19T18:13:05.821159Z","shell.execute_reply":"2025-11-19T18:14:43.564334Z"}},"outputs":[{"name":"stdout","text":"=== Simple LangChain AI Agent (rule-based) ===\nType 'exit', 'quit', or 'q' to end the conversation.\n\n","output_type":"stream"},{"output_type":"stream","name":"stdin","text":"You:  Hi\n"},{"name":"stdout","text":"[Intent: greeting | Sentiment: neutral]\nAgent: Hello! I am a simple AI agent here to chat with you and answer basic questions.\n\n","output_type":"stream"},{"output_type":"stream","name":"stdin","text":"You:  What can you do\n"},{"name":"stdout","text":"[Intent: information_request | Sentiment: neutral]\nAgent: I can explain what I am, what I can do, or help you think through simple questions step by step.\n\n","output_type":"stream"},{"output_type":"stream","name":"stdin","text":"You:  What are you?\n"},{"name":"stdout","text":"[Intent: general_conversation | Sentiment: neutral]\nAgent: I am an AI agent that analyzes your message and replies with a short, helpful response.\n\n","output_type":"stream"},{"output_type":"stream","name":"stdin","text":"You:  What is AI\n"},{"name":"stdout","text":"[Intent: general_conversation | Sentiment: neutral]\nAgent: I am an AI agent that analyzes your message and replies with a short, helpful response.\n\n","output_type":"stream"},{"output_type":"stream","name":"stdin","text":"You:  Who is the father of AI\n"},{"name":"stdout","text":"[Intent: general_conversation | Sentiment: neutral]\nAgent: I am an AI agent that analyzes your message and replies with a short, helpful response.\n\n","output_type":"stream"},{"output_type":"stream","name":"stdin","text":"You:  Can you write code?\n"},{"name":"stdout","text":"[Intent: information_request | Sentiment: neutral]\nAgent: I can explain what I am, what I can do, or help you think through simple questions step by step.\n\n","output_type":"stream"},{"output_type":"stream","name":"stdin","text":"You:  q\n"},{"name":"stdout","text":"Agent: Goodbye!\n","output_type":"stream"}],"execution_count":2},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}