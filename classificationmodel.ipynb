{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":10326308,"sourceType":"datasetVersion","datasetId":6393782}],"dockerImageVersionId":31192,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"\"\"\"\nClassification model for the provided heart_disease.csv dataset.\n\nTarget column: \"Heart Disease Status\" (Yes / No)\nFeatures:\n- Mix of numeric columns (Age, Blood Pressure, Cholesterol Level, BMI, etc.)\n- Categorical columns (Gender, Exercise Habits, Smoking, etc.)\n\"\"\"\n\nfrom dataclasses import dataclass\nfrom pathlib import Path\nfrom typing import Tuple, List\n\nimport pandas as pd\nfrom sklearn.compose import ColumnTransformer\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.impute import SimpleImputer\nfrom sklearn.metrics import accuracy_score, classification_report\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.pipeline import Pipeline\nfrom sklearn.preprocessing import OneHotEncoder, StandardScaler\n\n\n@dataclass\nclass TrainingConfig:\n    \"\"\"\n    Configuration for training the heart disease classifier.\n    \"\"\"\n    data_path: Path = Path(\"/kaggle/input/heart-disease/heart_disease.csv\")\n    target_column: str = \"Heart Disease Status\"\n    test_size: float = 0.2\n    random_state: int = 42\n\n\ndef load_data(config: TrainingConfig) -> pd.DataFrame:\n    \"\"\"\n    Load the dataset and perform basic sanity checks.\n    \"\"\"\n    if not config.data_path.is_file():\n        raise FileNotFoundError(\n            f\"Dataset file not found at {config.data_path.resolve()}. \"\n            \"Place heart_disease.csv in the same folder as this script.\"\n        )\n\n    df = pd.read_csv(config.data_path)\n\n    if config.target_column not in df.columns:\n        raise ValueError(\n            f\"Target column '{config.target_column}' not found. \"\n            f\"Available columns: {list(df.columns)}\"\n        )\n\n    return df\n\n\ndef split_features_and_target(\n    df: pd.DataFrame, config: TrainingConfig\n) -> Tuple[pd.DataFrame, pd.Series]:\n    \"\"\"\n    Separate feature matrix X and target vector y.\n    \"\"\"\n    X = df.drop(columns=[config.target_column])\n    y = df[config.target_column]\n\n    return X, y\n\n\ndef get_feature_types(X: pd.DataFrame) -> Tuple[List[str], List[str]]:\n    \"\"\"\n    Identify numeric and categorical feature columns.\n    \"\"\"\n    numeric_features = X.select_dtypes(include=[\"int64\", \"float64\"]).columns.tolist()\n    categorical_features = X.select_dtypes(include=[\"object\", \"bool\"]).columns.tolist()\n\n    return numeric_features, categorical_features\n\n\ndef build_pipeline(\n    numeric_features: List[str],\n    categorical_features: List[str],\n    config: TrainingConfig,\n) -> Pipeline:\n    \"\"\"\n    Build a preprocessing + model pipeline.\n\n    - Numeric features:\n        * Impute missing values with median.\n        * Standardize with StandardScaler.\n    - Categorical features:\n        * Impute missing values with most frequent category.\n        * One-hot encode.\n    - Model:\n        * RandomForestClassifier.\n    \"\"\"\n    numeric_transformer = Pipeline(\n        steps=[\n            (\"imputer\", SimpleImputer(strategy=\"median\")),\n            (\"scaler\", StandardScaler()),\n        ]\n    )\n\n    categorical_transformer = Pipeline(\n        steps=[\n            (\"imputer\", SimpleImputer(strategy=\"most_frequent\")),\n            (\"encoder\", OneHotEncoder(handle_unknown=\"ignore\")),\n        ]\n    )\n\n    preprocessor = ColumnTransformer(\n        transformers=[\n            (\"num\", numeric_transformer, numeric_features),\n            (\"cat\", categorical_transformer, categorical_features),\n        ]\n    )\n\n    model = RandomForestClassifier(\n        n_estimators=200,\n        random_state=config.random_state,\n        n_jobs=-1,\n    )\n\n    clf = Pipeline(\n        steps=[\n            (\"preprocess\", preprocessor),\n            (\"model\", model),\n        ]\n    )\n\n    return clf\n\n\ndef evaluate_model(model: Pipeline, X_test: pd.DataFrame, y_test: pd.Series) -> None:\n    \"\"\"\n    Evaluate the trained model on the test set and print metrics.\n    \"\"\"\n    y_pred = model.predict(X_test)\n\n    accuracy = accuracy_score(y_test, y_pred)\n    print(f\"Test Accuracy: {accuracy:.4f}\\n\")\n\n    print(\"Classification Report:\")\n    print(classification_report(y_test, y_pred))\n\n\ndef main() -> None:\n    \"\"\"\n    Run the full ML pipeline on heart_disease.csv.\n    \"\"\"\n    config = TrainingConfig()\n\n    # 1. Load data\n    df = load_data(config)\n\n    # 2. Split into features and target\n    X, y = split_features_and_target(df, config)\n\n    # 3. Identify feature types\n    numeric_features, categorical_features = get_feature_types(X)\n\n    # 4. Train-test split\n    X_train, X_test, y_train, y_test = train_test_split(\n        X,\n        y,\n        test_size=config.test_size,\n        random_state=config.random_state,\n        stratify=y,  # preserve class balance\n    )\n\n    # 5. Build pipeline and train\n    pipeline = build_pipeline(numeric_features, categorical_features, config)\n    pipeline.fit(X_train, y_train)\n\n    # 6. Evaluate\n    evaluate_model(pipeline, X_test, y_test)\n\n\nif __name__ == \"__main__\":\n    main()","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2025-11-19T17:29:17.356670Z","iopub.execute_input":"2025-11-19T17:29:17.356992Z","iopub.status.idle":"2025-11-19T17:29:19.671587Z","shell.execute_reply.started":"2025-11-19T17:29:17.356970Z","shell.execute_reply":"2025-11-19T17:29:19.670545Z"}},"outputs":[{"name":"stdout","text":"Test Accuracy: 0.8000\n\nClassification Report:\n              precision    recall  f1-score   support\n\n          No       0.80      1.00      0.89      1600\n         Yes       0.00      0.00      0.00       400\n\n    accuracy                           0.80      2000\n   macro avg       0.40      0.50      0.44      2000\nweighted avg       0.64      0.80      0.71      2000\n\n","output_type":"stream"},{"name":"stderr","text":"/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n  _warn_prf(average, modifier, msg_start, len(result))\n/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n  _warn_prf(average, modifier, msg_start, len(result))\n/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n  _warn_prf(average, modifier, msg_start, len(result))\n","output_type":"stream"}],"execution_count":3},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}